{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67063bbf-f570-439c-8b09-304dd3fcfefa",
   "metadata": {
    "id": "67063bbf-f570-439c-8b09-304dd3fcfefa",
    "user_expressions": []
   },
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133f46b-e39d-4c3b-b45b-0c722207c8d9",
   "metadata": {
    "id": "f133f46b-e39d-4c3b-b45b-0c722207c8d9",
    "user_expressions": []
   },
   "source": [
    "To use this notebook, first ensure the file paths are sent to the right location. You should have downloaded the dataset dev-2.0 and val-2.0 and put them in a folder named data. Then create a folder for each model you plan to train, and set that model path to that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1553e49-784a-46b3-af9f-44eb1f737e4c",
   "metadata": {
    "id": "a1553e49-784a-46b3-af9f-44eb1f737e4c",
    "user_expressions": []
   },
   "source": [
    "An important oversight of this notebook is that lack of storage for the test performance. I currently screenshot the cells. An improvement would be to save them so some type of csv file with the model name, total training time, and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2bf36-2199-4739-b617-4822073a932b",
   "metadata": {
    "id": "ccb2bf36-2199-4739-b617-4822073a932b",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Setup\n",
    "* Load modules\n",
    "* switch to cuda\n",
    "* read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a06f8e2-347d-4f3b-a7ff-b75caa01d01f",
   "metadata": {
    "id": "9a06f8e2-347d-4f3b-a7ff-b75caa01d01f",
    "outputId": "00f512cc-940d-4b65-b48e-b6b6d985456a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/fangyuan_li/.local/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load in required Packages\n",
    "import torch\n",
    "import json\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b8aa91-8369-4963-a30c-8de91a8be5ce",
   "metadata": {
    "id": "b5b8aa91-8369-4963-a30c-8de91a8be5ce",
    "outputId": "0d7e75d1-00e5-4552-c9c9-a614e348c79b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n"
     ]
    }
   ],
   "source": [
    "# Check the available device and use GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Print the device being used\n",
    "print(f'Working on {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c432d66-8549-4b81-86b6-f0b522d7c2d6",
   "metadata": {
    "id": "2c432d66-8549-4b81-86b6-f0b522d7c2d6",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Load Data, Set Up Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6593e63-a5ce-44bd-b17e-44f91c35be39",
   "metadata": {
    "id": "f6593e63-a5ce-44bd-b17e-44f91c35be39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    Read SQuAD data from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    - path: Path to the JSON file containing SQuAD data\n",
    "\n",
    "    Returns:\n",
    "    - contexts: List of contexts (passages)\n",
    "    - questions: List of questions\n",
    "    - answers: List of answers\n",
    "    \"\"\"\n",
    "    # Open the JSON file and load the data\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        squad = json.load(f)\n",
    "\n",
    "    # Initialize lists to store contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    # Iterate over groups in the SQuAD data\n",
    "    for group in squad.get('data', []):\n",
    "        # Iterate over paragraphs in the group\n",
    "        for passage in group.get('paragraphs', []):\n",
    "            # Get the context (passage)\n",
    "            context = passage.get('context', '')\n",
    "            # Iterate over questions and answers in the paragraph\n",
    "            for qa in passage.get('qas', []):\n",
    "                # Get the question\n",
    "                question = qa.get('question', '')\n",
    "                # Iterate over answers for the question\n",
    "                for answer in qa.get('answers', []):\n",
    "                    # Append context, question, and answer to their respective lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    # Return the lists of contexts, questions, and answers\n",
    "    return contexts, questions, answers\n",
    "\n",
    "def add_end_index(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # Check if the answer is correctly positioned\n",
    "        for offset in [0, -1, -2]:\n",
    "            if context[start_idx + offset:end_idx + offset] == gold_text:\n",
    "                # Update answer start and end indices\n",
    "                answer['answer_start'] = start_idx + offset\n",
    "                answer['answer_end'] = end_idx + offset\n",
    "                break  # Break loop once correct offset is found\n",
    "\n",
    "def add_token_positions(encodings, answers):\n",
    "    \"\"\"\n",
    "    Adds token positions for answers to encodings.\n",
    "\n",
    "    Parameters:\n",
    "    - encodings: Encodings object containing tokenized inputs\n",
    "    - answers: List of dictionaries containing answer positions\n",
    "\n",
    "    Returns:\n",
    "    None (modifies encodings in place)\n",
    "    \"\"\"\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Loop through each answer\n",
    "    for i, answer in enumerate(answers):\n",
    "        # Convert character positions to token positions\n",
    "        start_positions.append(encodings.char_to_token(i, answer['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answer['answer_end'] - 1))\n",
    "\n",
    "        # Handle cases where answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "    # Update encodings with start and end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for SQuAD.\n",
    "\n",
    "    Parameters:\n",
    "    - encodings: Encodings object containing tokenized inputs\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an item from the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - idx: Index of the item to retrieve\n",
    "\n",
    "        Returns:\n",
    "        Dictionary containing tensors for each key in the encodings\n",
    "        \"\"\"\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        Integer representing the length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.encodings.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badd25dc-7918-45be-bdea-9fee326480d2",
   "metadata": {
    "id": "badd25dc-7918-45be-bdea-9fee326480d2",
    "outputId": "8abd6691-053b-41f6-9d52-ab5225170b74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read training data\n",
    "contexts, questions, answers = read_data('/accounts/grad/fangyuan_li/259/data/train-v2.0.json')\n",
    "# Read validation data\n",
    "valid_contexts, valid_questions, valid_answers = read_data('/accounts/grad/fangyuan_li/259/data/val-v2.0.json')\n",
    "# Split train-v2.0 into train and test sets\n",
    "train_contexts = contexts[5000:]\n",
    "train_questions = questions[5000:]\n",
    "train_answers = answers[5000:]\n",
    "\n",
    "test_contexts = contexts[:5000]\n",
    "test_questions = questions[:5000]\n",
    "test_answers = answers[:5000]\n",
    "\n",
    "# Add indexes\n",
    "add_end_index(train_answers, train_contexts)\n",
    "add_end_index(valid_answers, valid_contexts)\n",
    "add_end_index(test_answers, test_contexts)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)\n",
    "\n",
    "# Add token positions for training data\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "# Add token positions for validation data\n",
    "add_token_positions(valid_encodings, valid_answers)\n",
    "# Add token positions for test data\n",
    "add_token_positions(test_encodings, test_answers)\n",
    "\n",
    "# Create training dataset\n",
    "train_dataset = SQuAD_Dataset(train_encodings)\n",
    "# Create validation dataset\n",
    "valid_dataset = SQuAD_Dataset(valid_encodings)\n",
    "# Create test dataset\n",
    "test_dataset = SQuAD_Dataset(test_encodings)\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf96737-7f0f-4409-9fa1-e2baabd8779a",
   "metadata": {
    "id": "3bf96737-7f0f-4409-9fa1-e2baabd8779a",
    "tags": []
   },
   "source": [
    "## Load Model + Freezing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3c75e5-6f35-442c-9fe4-ded4814e2f36",
   "metadata": {
    "id": "5a3c75e5-6f35-442c-9fe4-ded4814e2f36",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadc6410-33c2-450c-bced-66c479eeb091",
   "metadata": {
    "id": "cadc6410-33c2-450c-bced-66c479eeb091",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_layers(model, num_layers_to_freeze):\n",
    "    \"\"\"\n",
    "    Freeze the first 'num_layers_to_freeze' layers of a model.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model whose layers are to be frozen.\n",
    "    num_layers_to_freeze (int): The number of layers to freeze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Check for the typical attribute in BERT-like models\n",
    "    encoder_layers = model.bert.encoder.layer\n",
    "\n",
    "    # Freeze specified number of layers in the encoder\n",
    "    layer_count = 0\n",
    "    for layer in encoder_layers:\n",
    "        if layer_count < num_layers_to_freeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        layer_count += 1\n",
    "\n",
    "        # Break if we have frozen the desired number of layers\n",
    "        if layer_count >= num_layers_to_freeze:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed857ad6-8fd5-446e-a339-e59c93f3ebfb",
   "metadata": {
    "id": "ed857ad6-8fd5-446e-a339-e59c93f3ebfb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66f92471-3219-4187-9621-b03ae9c80621",
   "metadata": {
    "id": "66f92471-3219-4187-9621-b03ae9c80621",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 is frozen.\n",
      "Layer 2 is frozen.\n",
      "Layer 3 is frozen.\n",
      "Layer 4 is frozen.\n",
      "Layer 5 is frozen.\n",
      "Layer 6 is frozen.\n",
      "Layer 7 is frozen.\n",
      "Layer 8 is frozen.\n",
      "Layer 9 is frozen.\n",
      "Layer 10 is not frozen.\n",
      "Layer 11 is not frozen.\n",
      "Layer 12 is not frozen.\n",
      "Some layers are not fully frozen.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_if_layers_are_frozen(model):\n",
    "    \"\"\"\n",
    "    Check if the encoder layers of a model are frozen.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to check.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if all encoder layers are frozen, False otherwise.\n",
    "    \"\"\"\n",
    "    encoder_layers = model.bert.encoder.layer\n",
    "    all_frozen = True\n",
    "    layer_count = 0\n",
    "\n",
    "    for layer in encoder_layers:\n",
    "        layer_frozen = True\n",
    "        for param in layer.parameters():\n",
    "            if param.requires_grad:\n",
    "                layer_frozen = False\n",
    "                all_frozen = False\n",
    "        print(f\"Layer {layer_count + 1} is {'frozen' if layer_frozen else 'not frozen'}.\")\n",
    "        layer_count += 1\n",
    "\n",
    "    if all_frozen:\n",
    "        print(\"All layers are frozen.\")\n",
    "    else:\n",
    "        print(\"Some layers are not fully frozen.\")\n",
    "\n",
    "    return all_frozen\n",
    "\n",
    "# Now, check if the layers are frozen\n",
    "check_if_layers_are_frozen(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0cbf8-c362-4742-a6d7-d1e5b0e4adbd",
   "metadata": {
    "id": "dab0cbf8-c362-4742-a6d7-d1e5b0e4adbd",
    "user_expressions": []
   },
   "source": [
    "## One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7318397e-f484-4382-8dc9-a0ea78834fa0",
   "metadata": {
    "id": "7318397e-f484-4382-8dc9-a0ea78834fa0",
    "outputId": "cd9ebf08-9fdb-4e98-b0eb-e76859cf1755",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 1: 100%|██████████| 5114/5114 [26:47<00:00,  3.18it/s, loss=1.94] \n",
      "Epoch 2: 100%|██████████| 5114/5114 [26:48<00:00,  3.18it/s, loss=2.04] \n",
      "Epoch 3: 100%|██████████| 5114/5114 [26:48<00:00,  3.18it/s, loss=1.51] \n",
      "Epoch 4: 100%|██████████| 5114/5114 [26:48<00:00,  3.18it/s, loss=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/fangyuan_li/259/full_data/one_layer/tokenizer_config.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/one_layer/special_tokens_map.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/one_layer/vocab.txt',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/one_layer/added_tokens.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/one_layer/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/fangyuan_li/259/full_data/one_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0254853e-0207-4f82-98f5-919d188c7dda",
   "metadata": {
    "id": "0254853e-0207-4f82-98f5-919d188c7dda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/accounts/grad/fangyuan_li/259/full_data/one_layer_model_backup/backup.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a42944b-9de8-48fd-a37b-3704ddca658d",
   "metadata": {
    "id": "3a42944b-9de8-48fd-a37b-3704ddca658d",
    "outputId": "373740b3-96cc-4b23-869e-6d96d507adba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:43<00:00,  7.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1368e14e-f743-4df9-9d5b-ae4735170415",
   "metadata": {
    "id": "1368e14e-f743-4df9-9d5b-ae4735170415",
    "outputId": "814947b7-d6bf-490a-9e5f-85c5f5b6dbc6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6498602236421726\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8aab8-57f2-4562-9bf7-675f0428a8b9",
   "metadata": {
    "id": "80e8aab8-57f2-4562-9bf7-675f0428a8b9",
    "user_expressions": []
   },
   "source": [
    "## Two Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec2d199-b659-4ee9-96f8-951a0334173d",
   "metadata": {
    "id": "9ec2d199-b659-4ee9-96f8-951a0334173d",
    "outputId": "3cb18918-355b-4fb6-c2ee-d172179e2b42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 5114/5114 [27:34<00:00,  3.09it/s, loss=1.04] \n",
      "Epoch 2: 100%|██████████| 5114/5114 [27:35<00:00,  3.09it/s, loss=1.28] \n",
      "Epoch 3: 100%|██████████| 5114/5114 [27:33<00:00,  3.09it/s, loss=1.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/fangyuan_li/259/full_data/two_layer/tokenizer_config.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/two_layer/special_tokens_map.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/two_layer/vocab.txt',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/two_layer/added_tokens.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/two_layer/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 10)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/fangyuan_li/259/full_data/two_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0455acdf-55e4-4b1f-a0b9-fcb9bf7e4bd7",
   "metadata": {
    "id": "0455acdf-55e4-4b1f-a0b9-fcb9bf7e4bd7",
    "outputId": "e999e38a-e6d8-43f1-bf04-f12d2bd87eca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:42<00:00,  7.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6b54ba-6716-4bcd-a927-230c594242b7",
   "metadata": {
    "id": "cc6b54ba-6716-4bcd-a927-230c594242b7",
    "outputId": "0581266b-54dc-4ca1-96b9-750cfed52b71",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6901956869009584\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcefc07-9d8d-462f-9986-b86ff166c5bd",
   "metadata": {
    "id": "3dcefc07-9d8d-462f-9986-b86ff166c5bd",
    "user_expressions": []
   },
   "source": [
    "## Three Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbdb03a-a4c5-4c91-9d1e-a3755d8e34d5",
   "metadata": {
    "id": "7bbdb03a-a4c5-4c91-9d1e-a3755d8e34d5",
    "outputId": "b197096b-754f-4905-fef3-fde085896941",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 5114/5114 [28:27<00:00,  3.00it/s, loss=1.74] \n",
      "Epoch 2: 100%|██████████| 5114/5114 [28:31<00:00,  2.99it/s, loss=1]    \n",
      "Epoch 3: 100%|██████████| 5114/5114 [28:34<00:00,  2.98it/s, loss=1.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/fangyuan_li/259/full_data/three_layer/tokenizer_config.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/three_layer/special_tokens_map.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/three_layer/vocab.txt',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/three_layer/added_tokens.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/three_layer/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 9)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/fangyuan_li/259/full_data/three_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5befe89-d71d-49a3-822a-7a01e090c59d",
   "metadata": {
    "id": "a5befe89-d71d-49a3-822a-7a01e090c59d",
    "outputId": "de4f6bd3-96aa-463a-867a-90303b97866b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:43<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad29a08-b9f7-4b70-927d-c10b3b4d8af4",
   "metadata": {
    "id": "cad29a08-b9f7-4b70-927d-c10b3b4d8af4",
    "outputId": "b790f700-56ce-49df-8dec-997c700bde24",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134584664536742\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b3546-f349-42b3-beb3-e8d59a7472e6",
   "metadata": {
    "id": "a81b3546-f349-42b3-beb3-e8d59a7472e6",
    "user_expressions": []
   },
   "source": [
    "# Four Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96adb554-80b1-4f5a-9e3f-4eb98d2055bc",
   "metadata": {
    "id": "96adb554-80b1-4f5a-9e3f-4eb98d2055bc",
    "outputId": "8ca49e65-42d8-497f-dce6-8437ec1e17ad",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [17:13<00:00,  1.39it/s, loss=1.39] \n",
      "Epoch 2: 100%|██████████| 1441/1441 [17:13<00:00,  1.39it/s, loss=0.721]\n",
      "Epoch 3: 100%|██████████| 1441/1441 [17:12<00:00,  1.40it/s, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/four_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/four_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/four_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/four_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/four_layer/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 8)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/four_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d03ad5-623b-4471-8073-1bd4482b5cf9",
   "metadata": {
    "id": "e2d03ad5-623b-4471-8073-1bd4482b5cf9",
    "outputId": "8bb81513-fd59-41cf-e69a-93759c6c207d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:32<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871432793038253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701f6e4-094d-45ea-8774-45241d558427",
   "metadata": {
    "id": "6701f6e4-094d-45ea-8774-45241d558427",
    "user_expressions": []
   },
   "source": [
    "## Five Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feab615-587f-4c71-98e6-d8900f56bd02",
   "metadata": {
    "id": "3feab615-587f-4c71-98e6-d8900f56bd02",
    "outputId": "c3c6f520-d4da-4191-dabd-b1e160472c12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [17:38<00:00,  1.36it/s, loss=0.828]\n",
      "Epoch 2: 100%|██████████| 1441/1441 [17:35<00:00,  1.36it/s, loss=0.821]\n",
      "Epoch 3: 100%|██████████| 1441/1441 [17:36<00:00,  1.36it/s, loss=0.0673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/five_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/five_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/five_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/five_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/five_layer/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 7)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/five_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee35576-0a96-42b7-b750-7804e04e955e",
   "metadata": {
    "id": "0ee35576-0a96-42b7-b750-7804e04e955e",
    "outputId": "791f5ef8-e5f4-48f0-9a0b-dfbcd8eec00b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:33<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60295297197522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80d5e7-6ab8-41a4-980a-f848cd9da481",
   "metadata": {
    "id": "0a80d5e7-6ab8-41a4-980a-f848cd9da481",
    "user_expressions": []
   },
   "source": [
    "## Six Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb54552-5566-4e9e-804a-d606ea86dfe7",
   "metadata": {
    "id": "6cb54552-5566-4e9e-804a-d606ea86dfe7",
    "outputId": "eb7f55aa-ee08-46c3-e211-09e2d09fad30",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 5114/5114 [30:49<00:00,  2.76it/s, loss=1.47] \n",
      "Epoch 2: 100%|██████████| 5114/5114 [30:54<00:00,  2.76it/s, loss=0.594]\n",
      "Epoch 3: 100%|██████████| 5114/5114 [30:54<00:00,  2.76it/s, loss=1.04] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/fangyuan_li/259/full_data/six_layer/tokenizer_config.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/six_layer/special_tokens_map.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/six_layer/vocab.txt',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/six_layer/added_tokens.json',\n",
       " '/accounts/grad/fangyuan_li/259/full_data/six_layer/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 6)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/fangyuan_li/259/full_data/six_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c55262c-8f35-4fc4-96fc-37a484fafcb8",
   "metadata": {
    "id": "7c55262c-8f35-4fc4-96fc-37a484fafcb8",
    "outputId": "e4a03497-2e92-467c-895c-0d5babbd263d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:42<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7291333865814696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290be835-110a-40ec-951a-eedc5e9fe46a",
   "metadata": {
    "id": "290be835-110a-40ec-951a-eedc5e9fe46a",
    "user_expressions": []
   },
   "source": [
    "## Seven Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01ff72-ce03-45ac-b729-4fc66d9872e0",
   "metadata": {
    "id": "2e01ff72-ce03-45ac-b729-4fc66d9872e0",
    "outputId": "dd320e23-7163-4196-d0c0-e5573331f343",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [18:19<00:00,  1.31it/s, loss=2.54] \n",
      "Epoch 2: 100%|██████████| 1441/1441 [18:18<00:00,  1.31it/s, loss=0.552]\n",
      "Epoch 3: 100%|██████████| 1441/1441 [18:20<00:00,  1.31it/s, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/seven_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/seven_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/seven_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/seven_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/seven_layer/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 5)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/seven_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba0ec2-5b01-4063-bc74-d2c0173679f4",
   "metadata": {
    "id": "87ba0ec2-5b01-4063-bc74-d2c0173679f4",
    "outputId": "22f3bb3a-e2c7-483d-e0c8-9dfd03042bb8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:30<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6027418946637424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a5a4d-252d-4c8c-aa7c-23d343da45b0",
   "metadata": {
    "id": "6c3a5a4d-252d-4c8c-aa7c-23d343da45b0",
    "user_expressions": []
   },
   "source": [
    "## Eight Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4a94d-eb54-4c9d-a7fc-cc72fcf57617",
   "metadata": {
    "id": "53c4a94d-eb54-4c9d-a7fc-cc72fcf57617",
    "outputId": "fc60a4c2-3af0-46f8-e725-d56c347f8720",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [18:41<00:00,  1.28it/s, loss=0.531]\n",
      "Epoch 2: 100%|██████████| 1441/1441 [18:41<00:00,  1.29it/s, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/eight_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/eight_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/eight_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/eight_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/eight_layer/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 4)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/eight_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519c5db-1905-484e-899a-a84c47727bab",
   "metadata": {
    "id": "e519c5db-1905-484e-899a-a84c47727bab",
    "outputId": "2f7ecd91-d3b9-462e-a1b1-0cb96d2cfbe2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:30<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195506867112326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9422f-7e42-4c2c-82e8-3fb384068652",
   "metadata": {
    "id": "e2d9422f-7e42-4c2c-82e8-3fb384068652",
    "user_expressions": []
   },
   "source": [
    "## Nine Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1700e-df0a-48c5-9b74-3e1c247844a6",
   "metadata": {
    "id": "2ac1700e-df0a-48c5-9b74-3e1c247844a6",
    "outputId": "a2fce58e-f653-408a-a601-0e3d5fea5bf1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [19:02<00:00,  1.26it/s, loss=0.906]\n",
      "Epoch 2: 100%|██████████| 1441/1441 [19:04<00:00,  1.26it/s, loss=0.505]\n",
      "Epoch 3: 100%|██████████| 1441/1441 [19:04<00:00,  1.26it/s, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/nine_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/nine_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/nine_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/nine_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/nine_layer/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 3)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/nine_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796c650-8b3d-4156-8cfc-d5ce7c534c78",
   "metadata": {
    "id": "6796c650-8b3d-4156-8cfc-d5ce7c534c78",
    "outputId": "90bd5337-e7ca-440a-9f70-c4d627262239",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:30<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6203387087758504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5898ba8a-35d8-4ee8-99ba-7f5aac854c83",
   "metadata": {
    "id": "5898ba8a-35d8-4ee8-99ba-7f5aac854c83",
    "user_expressions": []
   },
   "source": [
    "# Ten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2268f-2999-4304-83df-7533cc3621f8",
   "metadata": {
    "id": "26e2268f-2999-4304-83df-7533cc3621f8",
    "outputId": "06222b2b-afc2-4c69-e659-68a38b0d765e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [19:27<00:00,  1.23it/s, loss=0.845]\n",
      "Epoch 2: 100%|██████████| 1441/1441 [19:28<00:00,  1.23it/s, loss=1.09] \n",
      "Epoch 3: 100%|██████████| 1441/1441 [19:27<00:00,  1.23it/s, loss=0.535] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/ten_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/ten_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/ten_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/ten_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/ten_layer/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 2)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/ten_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ba6e0-62a4-4001-8734-450a8e232044",
   "metadata": {
    "id": "dd1ba6e0-62a4-4001-8734-450a8e232044",
    "outputId": "3c75e81c-493c-4d76-e1d5-e130e119a0e4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:31<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626002617365291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affa90b-d2f5-4010-be71-db3051e2d95c",
   "metadata": {
    "id": "7affa90b-d2f5-4010-be71-db3051e2d95c",
    "user_expressions": []
   },
   "source": [
    "## Eleven Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56df5b-d3f9-48a0-879b-27a6101cb582",
   "metadata": {
    "id": "fd56df5b-d3f9-48a0-879b-27a6101cb582",
    "outputId": "700a63aa-f6f3-43a8-d45a-65e1aa1d7bce",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [19:46<00:00,  1.21it/s, loss=0.902]\n",
      "Epoch 2: 100%|██████████| 1441/1441 [19:48<00:00,  1.21it/s, loss=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/eleven_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/eleven_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/eleven_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/eleven_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/eleven_layer/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the first 11 layers of the model\n",
    "freeze_layers(model, 1)\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/eleven_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef17d4-f02e-432c-b1fb-8741e4822a96",
   "metadata": {
    "id": "96ef17d4-f02e-432c-b1fb-8741e4822a96",
    "outputId": "ac795235-6fe8-4d26-f747-1921017da0f4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:33<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626248874260484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45ba04-e729-40c7-9ff3-7f925adfd95e",
   "metadata": {
    "id": "ba45ba04-e729-40c7-9ff3-7f925adfd95e",
    "user_expressions": []
   },
   "source": [
    "## No Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed1d7f-9309-4cc1-994e-da1ba3e3abbc",
   "metadata": {
    "id": "37ed1d7f-9309-4cc1-994e-da1ba3e3abbc",
    "outputId": "eed01d18-babe-4c50-c685-ee0cd8dbdad8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [20:10<00:00,  1.19it/s, loss=1.07] \n",
      "Epoch 2: 100%|██████████| 1441/1441 [20:10<00:00,  1.19it/s, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/twelve_layer/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/twelve_layer/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/twelve_layer/vocab.txt',\n",
       " '/accounts/grad/sorenraj/twelve_layer/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/twelve_layer/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/twelve_layer'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= 1:  # Stops if no improvement in one epoch\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7b296-4e98-4a26-92a9-d67531f47a23",
   "metadata": {
    "id": "faa7b296-4e98-4a26-92a9-d67531f47a23",
    "outputId": "8d1b083e-5f20-4072-c072-1bb1781480d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:33<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6342979567763936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba07b43-9ed7-4417-96ba-f992bc6e4fd2",
   "metadata": {
    "id": "7ba07b43-9ed7-4417-96ba-f992bc6e4fd2",
    "user_expressions": []
   },
   "source": [
    "## Gradual Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755367b-ab50-4b08-ad98-a69e8bd2aa8e",
   "metadata": {
    "id": "e755367b-ab50-4b08-ad98-a69e8bd2aa8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unfreeze_last_layers(model, num_layers_to_unfreeze):\n",
    "    \"\"\"\n",
    "    Unfreeze the last 'num_layers_to_unfreeze' layers of a model.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model whose layers are to be unfrozen.\n",
    "    num_layers_to_unfreeze (int): The number of last layers to unfreeze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Initially freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Check for the typical attribute in BERT-like models\n",
    "    encoder_layers = model.bert.encoder.layer\n",
    "    total_layers = len(encoder_layers)\n",
    "\n",
    "    # Unfreeze the specified number of last layers\n",
    "    layers_to_start_unfreezing = total_layers - num_layers_to_unfreeze\n",
    "\n",
    "    for i, layer in enumerate(encoder_layers):\n",
    "        if i >= layers_to_start_unfreezing:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b62efa-8f53-4371-89a0-daed0a8c269a",
   "metadata": {
    "id": "43b62efa-8f53-4371-89a0-daed0a8c269a",
    "outputId": "8c52f286-29aa-41bf-a541-2a2556012aaf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 1441/1441 [16:06<00:00,  1.49it/s, loss=2.2] \n",
      "Epoch 2: 100%|██████████| 1441/1441 [16:08<00:00,  1.49it/s, loss=2.22] \n",
      "Epoch 3: 100%|██████████| 1441/1441 [16:09<00:00,  1.49it/s, loss=1.18] \n",
      "Epoch 4: 100%|██████████| 1441/1441 [16:10<00:00,  1.48it/s, loss=0.537]\n",
      "Epoch 5: 100%|██████████| 1441/1441 [16:10<00:00,  1.48it/s, loss=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreezing layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1441/1441 [10:43<00:00,  2.24it/s, loss=0.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreezing layer 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1441/1441 [11:38<00:00,  2.06it/s, loss=0.164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No improvement in validation loss for 3 epoch(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/accounts/grad/sorenraj/gradual_unfreezing/tokenizer_config.json',\n",
       " '/accounts/grad/sorenraj/gradual_unfreezing/special_tokens_map.json',\n",
       " '/accounts/grad/sorenraj/gradual_unfreezing/vocab.txt',\n",
       " '/accounts/grad/sorenraj/gradual_unfreezing/added_tokens.json',\n",
       " '/accounts/grad/sorenraj/gradual_unfreezing/tokenizer.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the path where the model and tokenizer will be saved\n",
    "model_path = '/accounts/grad/sorenraj/gradual_unfreezing'\n",
    "\n",
    "# Maximum number of epochs for training\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimizer definition\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Set model in training mode\n",
    "model.train()\n",
    "\n",
    "# Calculate batches per half epoch\n",
    "half_epoch_batches = len(train_loader) // 2\n",
    "\n",
    "# Function to save the model and optimizer state\n",
    "def save_checkpoint(epoch, batch_idx, model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'batch_idx': batch_idx,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt'))\n",
    "\n",
    "# Early stopping initialization\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "num_freeze = 11\n",
    "freeze_layers(model, num_freeze)\n",
    "\n",
    "\n",
    "# Iterate over epochs\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    # Reset loss for each epoch\n",
    "    total_loss = 0\n",
    "    # Create a progress bar for the training data\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    # Iterate over batches in the training data\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        # Zero gradients from previous iteration\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optim.step()\n",
    "\n",
    "        # Update progress bar description with current epoch\n",
    "        loop.set_description(f'Epoch {epoch+1}')\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation step after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in valid_loader:\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(valid_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    # If improving, keep training\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    # If not improving, unfreeze a layer or stop early\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= 3:  # Stops if no improvement in two epochs\n",
    "            print(f'Early stopping triggered. No improvement in validation loss for {epochs_no_improve} epoch(s).')\n",
    "            early_stop = True\n",
    "\n",
    "        elif epochs_no_improve <= 2 and epochs_no_improve > 0:\n",
    "            num_freeze -= 1\n",
    "\n",
    "            # Stop instead of unfreezing the \"13th\" layer\n",
    "            if num_freeze > 12:\n",
    "                early_stop = True\n",
    "                print('Stopping triggered. No improvement in validation loss on last layer')\n",
    "\n",
    "            # Otherwise, drop down a layer\n",
    "            else:\n",
    "                unfreeze_last_layers(model,12-num_freeze)\n",
    "                print(f'unfreezing layer {12-num_freeze}')\n",
    "\n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "# Optionally, save the model and tokenizer at the end of training\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37aec1-9848-4850-b2b4-a9a29148e70d",
   "metadata": {
    "id": "5c37aec1-9848-4850-b2b4-a9a29148e70d",
    "outputId": "fff3c231-0f04-4dec-cb01-cd2d99fe953a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [07:33<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5147015366547685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store accuracy values\n",
    "acc = []\n",
    "\n",
    "# Iterate over batches in the validation data\n",
    "for batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Move input tensors to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "\n",
    "        # Compute accuracy for start positions and end positions\n",
    "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "\n",
    "# Compute the average accuracy\n",
    "acc = sum(acc) / len(acc)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
